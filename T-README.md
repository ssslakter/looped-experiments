# Результаты
Для ускорения обучения, максимальное число точек в промпте $P$ при обучении было уменьшено до `n_points=20`, а максимальная размерность до `n_dims=10`. Максимальное число циклов $b$ равно `n_loops=20` и $T$ равно `n_loop_windows=5`. Шагов обучения - 75000, размер моделей также был уменьшен, для деталей см. [configs/](./configs/). 

По большей части эксперименты проводились на задачах классической линейной регрессии.

## Меньше токенов
Было проведено несколько экспериментов, когда на каждую следующую итерацию цикла передается на $d$ меньше токенов. То есть, после первой итерации цикла в модель передается $n-d$ токенов, после второй $n-2d$ и так далее, до минимального числа токенов $k$. При обучении это позволяет увеличить среднее количество итераций в секунду __в 1.7 раз__.

<img src="./media/T5_ex.png" height="180">
<img src="./media/T5_loop.png" height="180">

<img src="./media/T10_ex.png" height="185">
<img src="./media/T10_loop.png" height="185">

## Curriculum
Также было исследовано, как Curriculum влияет на качество моделей. Идея заключалась в том, чтобы постепенно увеличивать количество шагов на котором количество точек/измерений/циклов фиксировано, чтобы модель успела обучиться перед увеличением сложности задачи.

Таким образом помимо линейного curriculum, были опробованы следующие варианты, указанные на графиках. Все модели обучались с максимальным `n_loops=20` и `n_points=20`, и `n_loop_windows=5`. 

<img src="./media/clm_ex.png" height="197">
<img src="./media/clm_loop.png"height="197">

Как видно, при увеличении числа циклов модели сохраняют среднюю точность. Причем модель с линейным curriculum находит наиболее оптимальное решение для точек из промптов, где их размер, такой-же как в промптах из обучения. Однако при большем количестве, точность начинает падать, тогда как модели с curriculum $\sqrt{x}$ и $\cos{x}$, теряют её медленнее. Возможно из-за того, что длины промптов менялись неравномерно, модели смогли лучше адаптироваться под изменение их длины. В случае модели с $\log_2{x}$, то curriculum в ней не смог дойти до максимального числа циклов к концу итераций обучения, поэтому скорее всего модель не может обобщать на большее число циклов и точек.

