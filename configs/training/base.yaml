batch_size: 64
n_epoch: 10 # for infinite datasets, used only for more frequent evaluation
train_steps: 6000
eval_steps: 1000

learning_rate: 0.00015
weight_decay: 0.0
save_every_steps: 10000
curriculum:
  dims:
      start: 1
      end: 17
      inc: 1
      interval: 4000
  points:
      start: 11
      end: 41
      inc: 2
      interval: 4000